"""
SmartFlow AI Server - ìµœì¢… ëª¨ë¸ ë²„ì „
Two-Stage Ensemble (XGBoost + LightGBM + CatBoost)
SequenceEncoder + ì œí’ˆ ë¶„ë¥˜ ì‹œìŠ¤í…œ

Version: 3.0.0 (Custom Final)
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import numpy as np
import pandas as pd
import pickle
import os
import torch
import torch.nn as nn
import torch.nn.functional as F

app = FastAPI(title="SmartFlow AI Backend v3.0", version="3.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================================
# SequenceEncoder (PyTorch)
# ============================================================================

class SequenceEncoder(nn.Module):
    """
    14ì¼ ì‹œí€€ìŠ¤ â†’ 8ì°¨ì› ì„ë² ë”© ë³€í™˜
    CNN ê¸°ë°˜ ì‹œí€€ìŠ¤ ì¸ì½”ë”
    """
    def __init__(self, seq_len=14, emb_dim=8, dropout=0.2):
        super().__init__()
        self.conv1 = nn.Conv1d(1, 32, 3, padding=1)
        self.dropout1 = nn.Dropout(dropout)
        self.conv2 = nn.Conv1d(32, 16, 3, padding=1)
        self.dropout2 = nn.Dropout(dropout)
        self.pool = nn.AdaptiveAvgPool1d(1)
        self.fc = nn.Linear(16, emb_dim)
        self.dropout3 = nn.Dropout(dropout)
    
    def forward(self, x):
        x = x.permute(0, 2, 1)
        x = F.relu(self.conv1(x))
        x = self.dropout1(x)
        x = F.relu(self.conv2(x))
        x = self.dropout2(x)
        x = self.pool(x).squeeze(-1)
        x = F.relu(self.fc(x))
        x = self.dropout3(x)
        return x


def get_embeddings(sequences, encoder, device, batch_size=512):
    """ì‹œí€€ìŠ¤ ë¦¬ìŠ¤íŠ¸ â†’ ì„ë² ë”© ë³€í™˜"""
    encoder.eval()
    embeddings = []
    
    with torch.no_grad():
        for i in range(0, len(sequences), batch_size):
            batch = torch.FloatTensor(sequences[i:i+batch_size]).to(device)
            emb = encoder(batch).cpu().numpy()
            embeddings.append(emb)
    
    return np.vstack(embeddings) if embeddings else np.array([])


# ============================================================================
# ê¸€ë¡œë²Œ ëª¨ë¸ ë¡œë”
# ============================================================================

class SmartFlowModelLoader:
    """ëª¨ë¸ íŒ¨í‚¤ì§€ ë¡œë“œ ë° ê´€ë¦¬"""
    
    def __init__(self):
        self.package = None
        self.encoder = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model_paths = [
            "./ai_models/smartflow_final_custom.pkl",
            "../smartflow-backend_ai/ai_models/smartflow_final_custom.pkl",
            "/mnt/user-data/uploads/smartflow_final_custom.pkl",
        ]
        self.encoder_paths = [
            "./ai_models/encoder_custom.pth",
            "../smartflow-backend_ai/ai_models/encoder_custom.pth",
        ]
        self._load_model()
    
    def _load_model(self):
        """ëª¨ë¸ íŒ¨í‚¤ì§€ ë¡œë“œ"""
        # 1. ëª¨ë¸ íŒŒì¼ ë¡œë“œ
        for path in self.model_paths:
            if os.path.exists(path):
                try:
                    with open(path, 'rb') as f:
                        self.package = pickle.load(f)
                    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {path}")
                    break
                except Exception as e:
                    print(f"âŒ {path} ë¡œë“œ ì‹¤íŒ¨: {e}")
                    continue
        
        if self.package is None:
            print("âš ï¸  ëª¨ë¸ íŒŒì¼ ì—†ìŒ - ë”ë¯¸ ëª¨ë“œë¡œ ì‹¤í–‰")
            return
        
        # 2. Encoder ë¡œë“œ
        self.encoder = SequenceEncoder(dropout=0.2).to(self.device)
        
        # Option 1: encoder_stateê°€ íŒ¨í‚¤ì§€ì— í¬í•¨ëœ ê²½ìš°
        if 'encoder_state' in self.package:
            self.encoder.load_state_dict(self.package['encoder_state'])
            print("âœ… Encoder ë¡œë“œ (íŒ¨í‚¤ì§€ ë‚´ì¥)")
        
        # Option 2: ë³„ë„ íŒŒì¼ì—ì„œ ë¡œë“œ
        else:
            for path in self.encoder_paths:
                if os.path.exists(path):
                    try:
                        self.encoder.load_state_dict(torch.load(path, map_location=self.device))
                        print(f"âœ… Encoder ë¡œë“œ: {path}")
                        break
                    except Exception as e:
                        print(f"âŒ {path} ë¡œë“œ ì‹¤íŒ¨: {e}")
                        continue
        
        self.encoder.eval()
        
        # 3. ëª¨ë¸ ì •ë³´ ì¶œë ¥
        if isinstance(self.package, dict):
            print(f"ğŸ“¦ ëª¨ë¸ ë²„ì „: {self.package.get('version', 'unknown')}")
            print(f"ğŸ¯ ì„±ëŠ¥: {self.package.get('performance', {})}")
            print(f"ğŸ”‘ Horizon ê°œìˆ˜: {len(self.package.get('models', {}))}")
    
    def is_loaded(self):
        """ëª¨ë¸ ë¡œë“œ ì—¬ë¶€"""
        return self.package is not None and self.encoder is not None


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
model_loader = SmartFlowModelLoader()


# ============================================================================
# ì œí’ˆ ë¶„ë¥˜
# ============================================================================

def classify_product(stats: Dict) -> str:
    """
    ì œí’ˆ í†µê³„ ê¸°ë°˜ ë¶„ë¥˜
    
    Args:
        stats: {mean, std, cv, zero_ratio, ...}
    
    Returns:
        'Type A' | 'Stable' | 'Emergency' | 'Sparse'
    """
    mean_val = stats.get('mean', 0)
    cv = stats.get('cv', 0)
    zero_ratio = stats.get('zero_ratio', 0)
    
    if mean_val > 150 and cv < 0.3 and zero_ratio < 0.15:
        return 'Type A'
    elif mean_val > 50 and cv < 0.8 and zero_ratio < 0.3:
        return 'Stable'
    elif cv > 1.5 and zero_ratio < 0.5:
        return 'Emergency'
    else:
        return 'Sparse'


def get_product_type_features(product_type: str) -> List[int]:
    """ì œí’ˆ íƒ€ì… ì›-í•« ì¸ì½”ë”©"""
    types = ['Type A', 'Stable', 'Emergency', 'Sparse']
    return [1 if t.replace(' ', '_') == product_type.replace(' ', '_') else 0 for t in types]


# ============================================================================
# í”¼ì²˜ ìƒì„±
# ============================================================================

def create_features_for_prediction(
    sequence: List[float],
    product_stats: Dict,
    product_type: str,
    current_data: Dict,
    horizon_info: Dict
) -> np.ndarray:
    """
    ì˜ˆì¸¡ìš© 28ê°œ í”¼ì²˜ ìƒì„±
    
    Args:
        sequence: 14ì¼ ê³¼ê±° ìˆ˜ì£¼ëŸ‰ [day1, day2, ..., day14]
        product_stats: {mean, std, max, cv, zero_ratio}
        product_type: 'Type A' | 'Stable' | 'Emergency' | 'Sparse'
        current_data: {
            t_day_quantity: í˜„ì¬ Tì¼ ìˆ˜ì£¼ëŸ‰,
            last_year_quantity: ì‘ë…„ ë™ê¸° ìˆ˜ì£¼ëŸ‰,
            temperature: ê¸°ì˜¨,
            humidity: ìŠµë„,
            dow: ìš”ì¼(0-6),
            is_weekday: ì£¼ì¤‘ ì—¬ë¶€,
            month: ì›”(1-12)
        }
        horizon_info: {
            horizon: 1-4,
            future_dow: ë¯¸ë˜ ìš”ì¼,
            future_month: ë¯¸ë˜ ì›”,
            future_temp: ë¯¸ë˜ ê¸°ì˜¨,
            future_hum: ë¯¸ë˜ ìŠµë„
        }
    
    Returns:
        np.ndarray: shape (28,)
    """
    # í˜„ì¬ í”¼ì²˜ (15ê°œ)
    current_features = [
        current_data.get('t_day_quantity', 0),
        current_data.get('last_year_quantity', 0),
        product_stats.get('mean', 0),
        product_stats.get('std', 0),
        product_stats.get('max', 0),
        current_data.get('dow', 0),
        current_data.get('is_weekday', 1),
        current_data.get('month', 1),
        current_data.get('temperature', 20.0),
        current_data.get('humidity', 50.0),
        *get_product_type_features(product_type),  # 4ê°œ
        int(current_data.get('t_day_quantity', 0) == 0)  # is_zero
    ]
    
    # ë¯¸ë˜ í”¼ì²˜ (5ê°œ)
    future_features = [
        horizon_info.get('horizon', 1),
        horizon_info.get('future_dow', 0),
        horizon_info.get('future_month', 1),
        horizon_info.get('future_temp', 20.0),
        horizon_info.get('future_hum', 50.0)
    ]
    
    # ì„ë² ë”©ì€ ë³„ë„ë¡œ ì¶”ê°€ë¨ (8ê°œ)
    # ìµœì¢…: [embedding(8) + current(15) + future(5)] = 28ê°œ
    
    return np.array(current_features + future_features)


# ============================================================================
# Two-Stage ì˜ˆì¸¡
# ============================================================================

def predict_with_probability(
    features: np.ndarray,
    embeddings: np.ndarray,
    horizon: str
) -> tuple:
    """
    Two-Stage ì•™ìƒë¸” ì˜ˆì¸¡ (3ëª¨ë¸ í‰ê· )
    
    Args:
        features: shape (N, 20) - í˜„ì¬ + ë¯¸ë˜ í”¼ì²˜
        embeddings: shape (N, 8) - ì‹œí€€ìŠ¤ ì„ë² ë”©
        horizon: 'T+1', 'T+2', 'T+3', 'T+4'
    
    Returns:
        (probabilities, quantities)
    """
    if not model_loader.is_loaded():
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
    
    models = model_loader.package['models'].get(horizon)
    if not models:
        print(f"âš ï¸ {horizon} ëª¨ë¸ ì—†ìŒ - ê¸°ë³¸ê°’ ë°˜í™˜")
        return np.array([0.3]), np.array([50])
    
    # ìµœì¢… í”¼ì²˜ ê²°í•© [ì„ë² ë”©(8) + í”¼ì²˜(20)]
    X = np.hstack([embeddings, features])
    
    # Stage 1: Classification (3ëª¨ë¸ ì•™ìƒë¸”ì˜ í‰ê· )
    clf_models = models.get('clf')
    
    if not clf_models or not isinstance(clf_models, list):
        print(f"âš ï¸ {horizon} Stage 1 ëª¨ë¸ ì—†ìŒ - ê¸°ë³¸ê°’ ë°˜í™˜")
        return np.array([0.3]), np.array([50])
    
    # 3ê°œ ëª¨ë¸ì˜ í™•ë¥  í‰ê· 
    probas = sum(m.predict_proba(X)[:, 1] for m in clf_models) / len(clf_models)
    
    # Threshold ì ìš©
    threshold = models.get('th', 0.5)
    will_order = probas >= threshold
    
    # Stage 2: Regression (3ëª¨ë¸ ì•™ìƒë¸”ì˜ í‰ê· )
    reg_models = models.get('reg')
    
    if not reg_models or not isinstance(reg_models, list):
        print(f"âš ï¸ {horizon} Stage 2 ëª¨ë¸ ì—†ìŒ - í‰ê· ê°’ ì‚¬ìš©")
        quantities = np.zeros(len(X))
        quantities[will_order] = 50
        return probas, quantities
    
    quantities = np.zeros(len(X))
    
    if will_order.any():
        X_order = X[will_order]
        # 3ê°œ ëª¨ë¸ì˜ ì˜ˆì¸¡ í‰ê· 
        pred = sum(m.predict(X_order) for m in reg_models) / len(reg_models)
        quantities[will_order] = np.maximum(pred, 0)
    
    return probas, quantities


# ============================================================================
# Pydantic ëª¨ë¸
# ============================================================================

class ForecastRequest(BaseModel):
    product_code: str
    base_date: Optional[str] = None  # YYYY-MM-DD or None (ìµœì‹ )
    days: int = 4  # T+1 ~ T+4


class PredictionItem(BaseModel):
    date: str
    horizon: str
    product_type: str
    probability: float
    quantity: int
    recommend: str


class ForecastResponse(BaseModel):
    success: bool
    data: Dict


# ============================================================================
# API ì—”ë“œí¬ì¸íŠ¸
# ============================================================================

@app.get("/")
def root():
    return {
        "message": "SmartFlow AI Backend v3.0",
        "status": "running",
        "model_loaded": model_loader.is_loaded(),
        "version": "3.0.0",
        "approach": "Two-Stage Ensemble (XGBoost + LightGBM + CatBoost)",
        "features": {
            "sequence_encoder": True,
            "product_classification": True,
            "horizons": ["T+1", "T+2", "T+3", "T+4"]
        },
        "performance": model_loader.package.get('performance', {}) if model_loader.is_loaded() else {}
    }


@app.post("/api/forecast/predict")
def predict_demand(request: ForecastRequest):
    """
    ìˆ˜ìš” ì˜ˆì¸¡ API (ë©”ì¸)
    
    ì‹¤ì œ êµ¬í˜„ ì‹œ í•„ìš”í•œ ê²ƒ:
    1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° (ê³¼ê±° 14ì¼ ë°ì´í„° ì¡°íšŒ)
    2. ì œí’ˆ í†µê³„ ê³„ì‚°
    3. ë‚ ì”¨ ë°ì´í„° (ë˜ëŠ” í‰ê· ê°’)
    """
    try:
        if not model_loader.is_loaded():
            return {
                "success": False,
                "error": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
                "recommendation": "smartflow_final_custom.pkl íŒŒì¼ì„ ai_models/ í´ë”ì— ë°°ì¹˜í•˜ì„¸ìš”"
            }
        
        # =============================================
        # TODO: ì‹¤ì œ êµ¬í˜„ í•„ìš”
        # =============================================
        # 1. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê³¼ê±° 14ì¼ ë°ì´í„° ì¡°íšŒ
        sequence = get_product_sequence_from_db(request.product_code)  # êµ¬í˜„ í•„ìš”
        
        # 2. ì œí’ˆ í†µê³„ ê³„ì‚°
        product_stats = calculate_product_stats(sequence)  # êµ¬í˜„ í•„ìš”
        product_type = classify_product(product_stats)
        
        # 3. í˜„ì¬ ë°ì´í„° ì¤€ë¹„
        current_data = get_current_data(request.product_code)  # êµ¬í˜„ í•„ìš”
        
        # =============================================
        
        # ë”ë¯¸ ë°ì´í„° (ê°œë°œìš©)
        if len(sequence) == 0:
            sequence = list(np.random.randint(50, 200, 14))
            product_stats = {
                'mean': np.mean(sequence),
                'std': np.std(sequence),
                'max': np.max(sequence),
                'cv': np.std(sequence) / (np.mean(sequence) + 1e-6),
                'zero_ratio': 0.1
            }
            product_type = classify_product(product_stats)
            current_data = {
                't_day_quantity': sequence[-1],
                'last_year_quantity': int(sequence[-1] * 1.1),
                'temperature': 20.0,
                'humidity': 50.0,
                'dow': datetime.now().weekday(),
                'is_weekday': 1 if datetime.now().weekday() < 5 else 0,
                'month': datetime.now().month
            }
        
        # ì‹œí€€ìŠ¤ â†’ ì„ë² ë”©
        seq_tensor = np.array([sequence]).reshape(-1, 14, 1)
        embeddings = get_embeddings(seq_tensor, model_loader.encoder, model_loader.device)
        
        # Horizonë³„ ì˜ˆì¸¡
        predictions = []
        base_date = datetime.strptime(request.base_date, '%Y-%m-%d') if request.base_date else datetime.now()
        
        for i, horizon in enumerate(['T+1', 'T+2', 'T+3', 'T+4'][:request.days]):
            future_date = base_date + timedelta(days=i+1)
            
            horizon_info = {
                'horizon': i + 1,
                'future_dow': future_date.weekday(),
                'future_month': future_date.month,
                'future_temp': current_data.get('temperature', 20.0),
                'future_hum': current_data.get('humidity', 50.0)
            }
            
            features = create_features_for_prediction(
                sequence, product_stats, product_type,
                current_data, horizon_info
            ).reshape(1, -1)
            
            probas, quantities = predict_with_probability(features, embeddings, horizon)
            
            predictions.append({
                'date': future_date.strftime('%Y-%m-%d'),
                'horizon': horizon,
                'product_type': product_type,
                'probability': round(float(probas[0]), 2),
                'quantity': int(quantities[0]),
                'recommend': 'âœ… ë°œì£¼ ê¶Œì¥' if probas[0] >= 0.5 else 'âŒ ë°œì£¼ ë¶ˆí•„ìš”'
            })
        
        # ìš”ì•½ í†µê³„
        total_qty = sum(p['quantity'] for p in predictions)
        avg_prob = np.mean([p['probability'] for p in predictions])
        high_conf = sum(1 for p in predictions if p['probability'] >= 0.7)
        
        return {
            "success": True,
            "data": {
                "product_code": request.product_code,
                "product_type": product_type,
                "predictions": predictions,
                "summary": {
                    "total_quantity": total_qty,
                    "avg_probability": round(avg_prob, 2),
                    "high_confidence_days": high_conf,
                    "recommendation": f"ì´ {total_qty}ê°œ ì˜ˆìƒ, í‰ê·  í™•ë¥  {int(avg_prob*100)}%"
                }
            }
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")


@app.get("/api/model/status")
def get_model_status():
    """ëª¨ë¸ ìƒíƒœ í™•ì¸"""
    if not model_loader.is_loaded():
        return {
            "model_loaded": False,
            "error": "ëª¨ë¸ íŒŒì¼ ì—†ìŒ",
            "searched_paths": model_loader.model_paths
        }
    
    return {
        "model_loaded": True,
        "version": model_loader.package.get('version', 'unknown'),
        "performance": model_loader.package.get('performance', {}),
        "device": str(model_loader.device),
        "horizons": list(model_loader.package.get('models', {}).keys()),
        "encoder_loaded": model_loader.encoder is not None
    }


# ============================================================================
# í—¬í¼ í•¨ìˆ˜ (ì‹¤ì œ êµ¬í˜„ í•„ìš”)
# ============================================================================

def get_product_sequence_from_db(product_code: str) -> List[float]:
    """
    ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê³¼ê±° 14ì¼ ì‹œí€€ìŠ¤ ì¡°íšŒ
    
    TODO: ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° êµ¬í˜„
    - Order í…Œì´ë¸”ì—ì„œ ë‚ ì§œë³„ ì§‘ê³„
    - ë¹ˆ ë‚ ì§œëŠ” 0ìœ¼ë¡œ ì±„ì›€
    """
    # ì„ì‹œ ë”ë¯¸ ë°ì´í„°
    return []


def calculate_product_stats(sequence: List[float]) -> Dict:
    """ì‹œí€€ìŠ¤ì—ì„œ í†µê³„ ê³„ì‚°"""
    if not sequence:
        return {'mean': 0, 'std': 0, 'max': 0, 'cv': 0, 'zero_ratio': 0}
    
    arr = np.array(sequence)
    mean_val = np.mean(arr)
    std_val = np.std(arr)
    
    return {
        'mean': mean_val,
        'std': std_val,
        'max': np.max(arr),
        'cv': std_val / (mean_val + 1e-6),
        'zero_ratio': (arr == 0).mean()
    }


def get_current_data(product_code: str) -> Dict:
    """
    í˜„ì¬ ë°ì´í„° ì¡°íšŒ
    
    TODO: ì‹¤ì œ êµ¬í˜„
    - ìµœê·¼ ì£¼ë¬¸ ë°ì´í„°
    - ì‘ë…„ ë™ê¸° ë°ì´í„°
    - ë‚ ì”¨ ì •ë³´
    """
    return {}


# ============================================================================
# ì„œë²„ ì‹¤í–‰
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    print("\n" + "=" * 80)
    print("ğŸš€ SmartFlow AI Server v3.0 - Custom Final Model")
    print("=" * 80)
    uvicorn.run(app, host="0.0.0.0", port=8001)