"""
ìŠ¤ë§ˆíŠ¸ ì£¼ë¬¸ ì—…ë¡œë“œ ì‹œìŠ¤í…œ
- CSV/Excel ëª¨ë‘ ì§€ì›
- ì»¬ëŸ¼ ìë™ ì¸ì‹ + ìˆ˜ë™ ë§¤í•‘
- íšŒì‚¬ë³„ ë§ì¶¤ í¬ë§· ì§€ì›
"""

from fastapi import APIRouter, Depends, HTTPException, UploadFile, File
from sqlalchemy.orm import Session
from typing import List, Dict, Any, Optional
from pydantic import BaseModel
import pandas as pd
from datetime import datetime
import io
from database.database import get_db
from models.models import Order, User, Product
from api.auth import get_current_user

router = APIRouter(tags=["orders-upload"])

# ============================================
# ğŸ“Š ìŠ¤í‚¤ë§ˆ
# ============================================

class ColumnMapping(BaseModel):
    """ì»¬ëŸ¼ ë§¤í•‘ ì •ë³´"""
    order_number: Optional[str] = None  # ì£¼ë¬¸ë²ˆí˜¸ ì»¬ëŸ¼ëª…
    product_code: str  # ì œí’ˆì½”ë“œ ì»¬ëŸ¼ëª… (í•„ìˆ˜)
    product_name: Optional[str] = None  # ì œí’ˆëª… ì»¬ëŸ¼ëª…
    quantity: str  # ìˆ˜ëŸ‰ ì»¬ëŸ¼ëª… (í•„ìˆ˜)
    order_date: str  # ì£¼ë¬¸ì¼ ì»¬ëŸ¼ëª… (í•„ìˆ˜)
    due_date: Optional[str] = None  # ë‚©ê¸°ì¼ ì»¬ëŸ¼ëª…
    priority: Optional[str] = None  # ìš°ì„ ìˆœìœ„ ì»¬ëŸ¼ëª…
    status: Optional[str] = None  # ìƒíƒœ ì»¬ëŸ¼ëª…

class UploadPreviewResponse(BaseModel):
    """ì—…ë¡œë“œ ë¯¸ë¦¬ë³´ê¸° ì‘ë‹µ"""
    columns: List[str]  # íŒŒì¼ì˜ ì»¬ëŸ¼ ëª©ë¡
    sample_data: List[Dict[str, Any]]  # ìƒ˜í”Œ ë°ì´í„° (ìµœëŒ€ 5ê°œ)
    total_rows: int  # ì „ì²´ í–‰ ìˆ˜
    suggested_mapping: ColumnMapping  # AI ì¶”ì²œ ë§¤í•‘
    session_id: str  # ì„ì‹œ ì„¸ì…˜ ID

class ConfirmUploadRequest(BaseModel):
    """ì—…ë¡œë“œ í™•ì • ìš”ì²­"""
    session_id: str
    column_mapping: ColumnMapping

# ============================================
# ğŸ§  ìŠ¤ë§ˆíŠ¸ ì»¬ëŸ¼ ë§¤ì¹­ (AI ì¶”ì²œ)
# ============================================

class SmartColumnMatcher:
    """ì»¬ëŸ¼ëª…ì„ ë¶„ì„í•´ì„œ ìë™ìœ¼ë¡œ ë§¤í•‘ ì¶”ì²œ"""
    
    # ê° í•„ë“œë³„ ê°€ëŠ¥í•œ ì»¬ëŸ¼ëª… íŒ¨í„´
    PATTERNS = {
        'product_code': [
            'ì œí’ˆì½”ë“œ', 'í’ˆëª©ì½”ë“œ', 'í’ˆë²ˆ', 'ì œí’ˆë²ˆí˜¸', 'product_code', 'product code', 
            'item_code', 'item code', 'sku', 'part_number', 'í’ˆëª©ë²ˆí˜¸'
        ],
        'product_name': [
            'ì œí’ˆëª…', 'í’ˆëª©ëª…', 'ì œí’ˆì´ë¦„', 'product_name', 'product name', 
            'item_name', 'item name', 'í’ˆëª…', 'í’ˆëª©'
        ],
        'quantity': [
            'ìˆ˜ëŸ‰', 'ì£¼ë¬¸ìˆ˜ëŸ‰', 'ë°œì£¼ìˆ˜ëŸ‰', 'quantity', 'qty', 'amount', 
            'order_quantity', 'order qty', 'ê°œìˆ˜', 'ì£¼ë¬¸ëŸ‰'
        ],
        'order_date': [
            'ì£¼ë¬¸ì¼', 'ë°œì£¼ì¼', 'ì£¼ë¬¸ë‚ ì§œ', 'ë°œì£¼ë‚ ì§œ', 'order_date', 'order date',
            'date', 'ë‚ ì§œ', 'ì¼ì', 'order_time', 'ì£¼ë¬¸ì‹œê°„'
        ],
        'due_date': [
            'ë‚©ê¸°ì¼', 'ë‚©ê¸°', 'ì˜ˆì •ì¼', 'due_date', 'due date', 'delivery_date',
            'delivery date', 'ë‚©í’ˆì¼', 'ì¶œê³ ì˜ˆì •ì¼'
        ],
        'order_number': [
            'ì£¼ë¬¸ë²ˆí˜¸', 'ë°œì£¼ë²ˆí˜¸', 'order_number', 'order number', 'order_no',
            'po_number', 'po number', 'ì£¼ë¬¸ì„œë²ˆí˜¸'
        ]
    }
    
    @classmethod
    def suggest_mapping(cls, columns: List[str]) -> ColumnMapping:
        """ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì„œ ìë™ ë§¤í•‘ ì¶”ì²œ"""
        
        # ì»¬ëŸ¼ëª…ì„ ì†Œë¬¸ìë¡œ ë³€í™˜ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
        columns_lower = [col.lower().strip() for col in columns]
        
        mapping = {}
        
        for field, patterns in cls.PATTERNS.items():
            matched = None
            for i, col in enumerate(columns_lower):
                for pattern in patterns:
                    if pattern.lower() in col or col in pattern.lower():
                        matched = columns[i]  # ì›ë³¸ ì»¬ëŸ¼ëª… ì‚¬ìš©
                        break
                if matched:
                    break
            
            if matched:
                mapping[field] = matched
        
        # í•„ìˆ˜ í•„ë“œ ì²´í¬
        if 'product_code' not in mapping:
            mapping['product_code'] = columns[0] if columns else None
        if 'quantity' not in mapping:
            # 'ìˆ˜ëŸ‰'ì´ í¬í•¨ëœ ì»¬ëŸ¼ ì°¾ê¸°
            qty_col = next((col for col in columns if 'ìˆ˜ëŸ‰' in col.lower() or 'qty' in col.lower()), None)
            mapping['quantity'] = qty_col or (columns[1] if len(columns) > 1 else None)
        if 'order_date' not in mapping:
            # 'ë‚ ì§œ'ë‚˜ 'date'ê°€ í¬í•¨ëœ ì»¬ëŸ¼ ì°¾ê¸°
            date_col = next((col for col in columns if 'ë‚ ì§œ' in col.lower() or 'date' in col.lower()), None)
            mapping['order_date'] = date_col or (columns[2] if len(columns) > 2 else None)
        
        return ColumnMapping(**mapping)

# ============================================
# ğŸ“ íŒŒì¼ íŒŒì‹± (CSV/Excel)
# ============================================

class FileParser:
    """CSVì™€ Excel íŒŒì¼ì„ íŒŒì‹±"""
    
    @staticmethod
    async def parse_file(file: UploadFile) -> pd.DataFrame:
        """íŒŒì¼ ì½ê¸° (CSV ë˜ëŠ” Excel)"""
        contents = await file.read()
        
        try:
            # Excel ì‹œë„
            if file.filename.endswith(('.xlsx', '.xls')):
                df = pd.read_excel(io.BytesIO(contents))
            # CSV ì‹œë„ (ì—¬ëŸ¬ ì¸ì½”ë”© ìë™ ê°ì§€)
            elif file.filename.endswith('.csv'):
                # UTF-8 ì‹œë„
                try:
                    df = pd.read_csv(io.BytesIO(contents), encoding='utf-8')
                except:
                    # CP949 (í•œê¸€ Windows) ì‹œë„
                    try:
                        df = pd.read_csv(io.BytesIO(contents), encoding='cp949')
                    except:
                        # EUC-KR ì‹œë„
                        df = pd.read_csv(io.BytesIO(contents), encoding='euc-kr')
            else:
                raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤")
            
            # ë¹ˆ í–‰ ì œê±°
            df = df.dropna(how='all')
            
            # ì»¬ëŸ¼ëª… ì •ë¦¬ (ê³µë°± ì œê±°)
            df.columns = df.columns.str.strip()
            
            return df
            
        except Exception as e:
            raise ValueError(f"íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")

# ============================================
# ğŸ¯ ì„ì‹œ ì„¸ì…˜ ì €ì¥ì†Œ
# ============================================

# ê°„ë‹¨í•œ ì¸ë©”ëª¨ë¦¬ ì €ì¥ì†Œ (ì‹¤ì œë¡œëŠ” Redis ì‚¬ìš© ê¶Œì¥)
upload_sessions = {}

def create_session_id(user_id: int) -> str:
    """ì„¸ì…˜ ID ìƒì„±"""
    import hashlib
    import time
    timestamp = str(time.time())
    return hashlib.md5(f"{user_id}_{timestamp}".encode()).hexdigest()

# ============================================
# ğŸš€ API ì—”ë“œí¬ì¸íŠ¸
# ============================================

@router.post("/upload-preview")
async def preview_upload(
    file: UploadFile = File(...),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    Step 1: íŒŒì¼ ì—…ë¡œë“œ ë¯¸ë¦¬ë³´ê¸°
    - ì»¬ëŸ¼ ëª©ë¡ ë°˜í™˜
    - ìƒ˜í”Œ ë°ì´í„° ë°˜í™˜
    - AI ì¶”ì²œ ë§¤í•‘ ë°˜í™˜
    """
    
    try:
        # íŒŒì¼ íŒŒì‹±
        df = await FileParser.parse_file(file)
        
        if df.empty:
            raise HTTPException(status_code=400, detail="ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤")
        
        # ì»¬ëŸ¼ ëª©ë¡
        columns = df.columns.tolist()
        
        # ìƒ˜í”Œ ë°ì´í„° (ìµœëŒ€ 5ê°œ)
        sample_data = df.head(5).fillna('').to_dict('records')
        
        # AI ì¶”ì²œ ë§¤í•‘
        suggested_mapping = SmartColumnMatcher.suggest_mapping(columns)
        
        # ì„¸ì…˜ ìƒì„± ë° ë°ì´í„° ì„ì‹œ ì €ì¥
        session_id = create_session_id(current_user.id)
        upload_sessions[session_id] = {
            'user_id': current_user.id,
            'dataframe': df,
            'timestamp': datetime.now()
        }
        
        return {
            "success": True,
            "data": {
                "columns": columns,
                "sample_data": sample_data,
                "total_rows": len(df),
                "suggested_mapping": suggested_mapping.dict(),
                "session_id": session_id
            }
        }
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {str(e)}")

@router.post("/upload-confirm")
async def confirm_upload(
    request: ConfirmUploadRequest,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    Step 2: ì—…ë¡œë“œ í™•ì •
    - ì‚¬ìš©ìê°€ í™•ì¸í•œ ë§¤í•‘ìœ¼ë¡œ ë°ì´í„° ì €ì¥
    """
    
    try:
        # ì„¸ì…˜ í™•ì¸
        if request.session_id not in upload_sessions:
            raise HTTPException(status_code=400, detail="ì„¸ì…˜ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        
        session = upload_sessions[request.session_id]
        
        # ê¶Œí•œ í™•ì¸
        if session['user_id'] != current_user.id:
            raise HTTPException(status_code=403, detail="ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤")
        
        df = session['dataframe']
        mapping = request.column_mapping
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        if not mapping.product_code or not mapping.quantity or not mapping.order_date:
            raise HTTPException(
                status_code=400, 
                detail="ì œí’ˆì½”ë“œ, ìˆ˜ëŸ‰, ì£¼ë¬¸ì¼ì€ í•„ìˆ˜ ì…ë ¥ì…ë‹ˆë‹¤"
            )
        
        # ë°ì´í„° ë³€í™˜ ë° ì €ì¥
        success_count = 0
        error_count = 0
        error_messages = []
        
        for idx, row in df.iterrows():
            try:
                # ë§¤í•‘ëœ ì»¬ëŸ¼ì—ì„œ ê°’ ì¶”ì¶œ
                product_code = str(row[mapping.product_code]).strip()
                quantity = int(float(row[mapping.quantity]))
                
                # ë‚ ì§œ íŒŒì‹±
                order_date_str = str(row[mapping.order_date])
                try:
                    order_date = pd.to_datetime(order_date_str).date()
                except:
                    order_date = datetime.now().date()
                
                # ì„ íƒì  í•„ë“œ
                product_name = str(row[mapping.product_name]).strip() if mapping.product_name and mapping.product_name in df.columns else product_code
                order_number = str(row[mapping.order_number]) if mapping.order_number and mapping.order_number in df.columns else f"ORD-{current_user.id}-{idx}"
                
                # ì œí’ˆì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
                product = db.query(Product).filter(
                    Product.product_code == product_code,
                    Product.user_id == current_user.id
                ).first()
                
                if not product:
                    # ì œí’ˆ ìë™ ìƒì„±
                    product = Product(
                        user_id=current_user.id,
                        product_code=product_code,
                        product_name=product_name
                    )
                    db.add(product)
                    db.flush()  # ID ìƒì„±
                
                # ì£¼ë¬¸ ìƒì„±
                order = Order(
                    user_id=current_user.id,
                    order_number=order_number,
                    product_code=product_code,
                    product_name=product_name,
                    quantity=quantity,
                    due_date=order_date,
                    status='completed',  # ê³¼ê±° ë°ì´í„°ëŠ” ì™„ë£Œ ìƒíƒœ
                    created_at=datetime.combine(order_date, datetime.min.time())
                )
                db.add(order)
                success_count += 1
                
            except Exception as e:
                error_count += 1
                error_messages.append(f"í–‰ {idx + 2}: {str(e)}")
                if len(error_messages) > 10:  # ì—ëŸ¬ ë©”ì‹œì§€ ìµœëŒ€ 10ê°œ
                    break
        
        # ì»¤ë°‹
        db.commit()
        
        # ì„¸ì…˜ ì‚­ì œ
        del upload_sessions[request.session_id]
        
        return {
            "success": True,
            "message": f"ì£¼ë¬¸ {success_count}ê°œ ì—…ë¡œë“œ ì™„ë£Œ!",
            "data": {
                "success_count": success_count,
                "error_count": error_count,
                "error_messages": error_messages[:10]
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

@router.get("/template")
async def download_template(
    current_user: User = Depends(get_current_user)
):
    """ì£¼ë¬¸ ì—…ë¡œë“œ í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ"""
    
    # í…œí”Œë¦¿ ë°ì´í„°
    template_data = {
        'ì œí’ˆì½”ë“œ': ['PROD-001', 'PROD-002', 'PROD-003'],
        'ì œí’ˆëª…': ['ì „ìë¶€í’ˆ A', 'ë‚˜ì‚¬ ì„¸íŠ¸ B', 'ì ˆì—°ì¬ C'],
        'ìˆ˜ëŸ‰': [100, 200, 150],
        'ì£¼ë¬¸ì¼': ['2024-01-01', '2024-01-02', '2024-01-03'],
        'ì£¼ë¬¸ë²ˆí˜¸': ['ORD-001', 'ORD-002', 'ORD-003']
    }
    
    df = pd.DataFrame(template_data)
    
    # Excel íŒŒì¼ ìƒì„±
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='ì£¼ë¬¸ë‚´ì—­')
    
    output.seek(0)
    
    from fastapi.responses import StreamingResponse
    return StreamingResponse(
        output,
        media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
        headers={'Content-Disposition': 'attachment; filename=ì£¼ë¬¸ë‚´ì—­_í…œí”Œë¦¿.xlsx'}
    )